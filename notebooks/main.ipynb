{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378917f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (4.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (2.3.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from pyspark) (0.10.9.9)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (21.0.0)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (2.32.5)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.7.0)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.2-cp313-cp313-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.14.1)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl.metadata (77 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\my lap\\appdata\\roaming\\python\\python313\\site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.2.1)\n",
      "Downloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-1.0.1-py3-none-any.whl (503 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.8/2.9 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 10.3 MB/s  0:00:00\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.13.2-cp313-cp313-win_amd64.whl (452 kB)\n",
      "Downloading multidict-6.7.0-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading propcache-0.4.1-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Installing collected packages: xxhash, shellingham, propcache, multidict, httpcore, hf-xet, frozenlist, dill, aiohappyeyeballs, yarl, typer-slim, multiprocess, httpx, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "\n",
      "   ---- -----------------------------------  2/17 [propcache]\n",
      "   --------- ------------------------------  4/17 [httpcore]\n",
      "   --------- ------------------------------  4/17 [httpcore]\n",
      "   --------- ------------------------------  4/17 [httpcore]\n",
      "   ---------------- -----------------------  7/17 [dill]\n",
      "   ---------------- -----------------------  7/17 [dill]\n",
      "   ---------------- -----------------------  7/17 [dill]\n",
      "   ---------------- -----------------------  7/17 [dill]\n",
      "   ------------------ ---------------------  8/17 [aiohappyeyeballs]\n",
      "   --------------------- ------------------  9/17 [yarl]\n",
      "   ----------------------- ---------------- 10/17 [typer-slim]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ---------------------------- ----------- 12/17 [httpx]\n",
      "   ---------------------------- ----------- 12/17 [httpx]\n",
      "   ---------------------------- ----------- 12/17 [httpx]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   -------------------------------- ------- 14/17 [huggingface-hub]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ----------------------------------- ---- 15/17 [aiohttp]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [datasets]\n",
      "   ---------------------------------------- 17/17 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 datasets-4.3.0 dill-0.4.0 frozenlist-1.8.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.0.1 multidict-6.7.0 multiprocess-0.70.16 propcache-0.4.1 shellingham-1.5.4 typer-slim-0.20.0 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark pandas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7883a856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải bộ dữ liệu 'zeroshot/twitter-financial-news-sentiment'...\n",
      "Đã lưu thành công 11931 bản ghi vào tệp: data\\twitter_financial_sentiment.csv\n",
      "Hoàn tất chuẩn bị dữ liệu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY LAP\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\file_download.py:120: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\MY LAP\\.cache\\huggingface\\hub\\datasets--zeroshot--twitter-financial-news-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "\n",
      "Generating train split:   0%|          | 0/9543 [00:00<?, ? examples/s]\n",
      "Generating train split: 100%|██████████| 9543/9543 [00:00<00:00, 230678.86 examples/s]\n",
      "\n",
      "Generating validation split:   0%|          | 0/2388 [00:00<?, ? examples/s]\n",
      "Generating validation split: 100%|██████████| 2388/2388 [00:00<00:00, 299727.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "! python \"C:\\Users\\MY LAP\\Desktop\\lab05\\dataset\\prepare_dataset.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d7c5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Python executable 'python3', defaulting to 'C:\\Users\\MY LAP\\AppData\\Roaming\\Python\\Python313\\site-packages\\pyspark\\bin\\..' for SPARK_HOME environment variable. Please install Python or specify the correct Python executable in PYSPARK_DRIVER_PYTHON or PYSPARK_PYTHON environment variable to detect SPARK_HOME safely.\n",
      "Đang tải dữ liệu từ data/twitter_financial_sentiment.csv...\n",
      "Dữ liệu đã được chia thành tập train và test.\n",
      "\n",
      "Đang xây dựng Pipeline 1: TF-IDF + Logistic Regression (Baseline)\n",
      "Đang xây dựng Pipeline 2: TF-IDF + Naive Bayes (Improvement)\n",
      "Đang xây dựng Pipeline 3: Word2Vec + Logistic Regression (Improvement)\n",
      "\n",
      "--- Đang huấn luyện: Baseline (TF-IDF + LR) ---\n",
      "--- Đang đánh giá: Baseline (TF-IDF + LR) ---\n",
      "\n",
      "--- Đang huấn luyện: Improvement (TF-IDF + NB) ---\n",
      "--- Đang đánh giá: Improvement (TF-IDF + NB) ---\n",
      "\n",
      "--- Đang huấn luyện: Improvement (Word2Vec + LR) ---\n",
      "--- Đang đánh giá: Improvement (Word2Vec + LR) ---\n",
      "\n",
      "---  KẾT QUẢ SO SÁNH HIỆU SUẤT ---\n",
      "--------------------------------------------------\n",
      "Mô hình                        | Accuracy   | F1-Score  \n",
      "--------------------------------------------------\n",
      "Baseline (TF-IDF + LR)         | 0.7273     | 0.7263    \n",
      "Improvement (TF-IDF + NB)      | 0.6881     | 0.7010    \n",
      "Improvement (Word2Vec + LR)    | 0.6678     | 0.5621    \n",
      "--------------------------------------------------\n",
      "SUCCESS: The process with PID 13848 (child process of PID 19496) has been terminated.\n",
      "SUCCESS: The process with PID 19496 (child process of PID 12028) has been terminated.\n",
      "SUCCESS: The process with PID 12028 (child process of PID 13560) has been terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "\n",
      "[Stage 2:>                                                          (0 + 1) / 1]\n",
      "\n",
      "                                                                                \n",
      "25/10/29 13:14:15 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "\n",
      "[Stage 30:>                                                         (0 + 1) / 1]\n",
      "\n",
      "                                                                                \n"
     ]
    }
   ],
   "source": [
    "! python \"C:\\Users\\MY LAP\\Desktop\\lab05\\test\\lab5_spark_sentiment_analysis.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
